# Tell hydra how to construct the config from sub confs by default
defaults:
  - model: hl_unet
  - loss: hl
  - lr_sched: none
  - dataset: j0126_v2_c350_2val
  - data_prep: v2
  - knossos_raw_to_zarr: default
  - cloudvolume_raw_to_zarr: default
  - _self_

# Common path prefix
path_prefix: ${oc.env:HOME}/lsdex

# Short description for manually tagging runs, to be set via hydra CLI
descr: ''

# Generate random two-word codename using custom omgegaconf resolver
shortname: ${randomname:}${descr}

# Time stamp in ISO 8601-like format
# timestamp: ${now:%Y-%m-%d_%H-%M-%S}
timestamp: ${now:%m-%d_%H-%M}

# Version tag
v: v1

hydra:
  run:
    # Where to write logs and config copies
    dir: ${path_prefix}/${v}/${hydra.job.name}/${timestamp}_${shortname}

# Log config values with module logger
log_config: true

enable_zarr_results: false  # warning: concurrent writes possible
device: cuda


labels:
  aff:
    nhood: [[-1, 0, 0], [0, -1, 0], [0, 0, -1]]
  lsd:
    sigma: 120
    downsample: 2
#    sigma: 108
#    downsample: 4


wandb:
  ## These are directly passed to wandb.init() as **kwargs
  init_cfg:
    dir: ${path_prefix}/${v}/
    entity: mdth
    project: nseg_hl6
    name: ${shortname}
    tags:
      - mtlsd
  # Visualization options
  vis:
    enable_binary_labels: true
  # Log metrics per cube with filename suffix in addition to mean metrics
  enable_per_cube_metrics: true
  # Include only files with these extensions
  code_include_fn_exts: ['.py', '.json', '.yaml', '.yml', '.sh', '.txt']


augmentations:
  enable_elastic: true

training:
  iterations: 400001
  save_every: 5000
  # save_every: 2
  # seed: 0  # TODO: Enable in training, make sure forked processes reseed!
  first_eval_at_step: 11

  ## Performance options

#  num_workers: auto
#  num_workers: 0
  num_workers: 32
#  num_workers: 2
  enable_amp: true
  # enable_amp: false
  enable_dynamo: false
  enable_cudnn_benchmark: true
  # enable_cudnn_benchmark: false

  ## Main hyperparams

  batch_size: 1
  lr: 0.5e-4
  adam_betas: [0.95, 0.999]

#  batch_size: 8
#  lr: 4.0e-4

#  batch_size: 16
#  lr: 1.0e-3

  save_jit: null
  save_full_state_dicts: false  # Full state dicts can be huge, so only save if needed


# TODO: eval subconfigs (default - testing; default - validation; agglo thresh sweep - validation)
eval:
  max_eval_cubes: null  # Don't limit eval cubes (default)
#  max_eval_cubes: 1  # Only do eval on first cube, skip others
  cube_root: ${dataset.val_root}
  # checkpoint_path: /u/mdraw/lsdex/v1/train_mtlsd/06-14_16-57_intense-margin_mse_sum_numel/model_checkpoint_14800.pth
  # checkpoint_path: /u/mdraw/lsdex/v1/train_mtlsd/06-19_17-41_andante-story_andmask_mse_w0.5/model_checkpoint_7000.pt
#  checkpoint_path: /cajal/scratch/projects/misc/mdraw/lsdex/v1/train_mtlsd/06-23_05-46_crunchy-staff/model_checkpoint_8000.pt
  checkpoint_path: null
  result_zarr_root: ${path_prefix}/${v}/eval_zarr/
  fragment_threshold: 0.5

  ## waterz segmentation agglomeration config
  waterz_threshold_sweep_linspace: # [0.0, 0.2, 201]  # Don't use that on the test set

  merge_function: hist_quant_75
  threshold: 0.1
#  threshold: 0.4

  # merge_function: mean
  # threshold: 0.043

  output_cfg:
    pred_affs: {out_dims: 3, out_dtype: uint8,   squeeze: true, scale: 255 }
    pred_lsds: {out_dims: 10, out_dtype: uint8,   squeeze: true, scale: 255 }
    # TODO: More concise output cfg
#    pred_boundaries: {out_dims: 1, out_dtype: uint8,   squeeze: true, scale: 255 }
#    pred_hardness: {out_dims: 1, out_dtype: float32, squeeze: true, scale: 1.0 }
#    pred_boundary_distmap: {out_dims:  1, out_dtype: float32, squeeze: true, scale: 1.0}


  # roi_shape: [250, 250, 250]
  roi_shape: null

  write_groups:
    - raw0
    - gt_seg
    - cropped_pred_frag
    - cropped_pred_seg
    - cropped_pred_hardness0

