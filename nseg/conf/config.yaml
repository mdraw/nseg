# Tell hydra how to construct the config from sub confs by default
defaults:
  - model: funlib_unet
  - dataset: j0126
  - data_prep: default
  - _self_

# Common path prefix
path_prefix: ${oc.env:HOME}/lsdex

# Short description for manually tagging runs, to be set via hydra CLI
descr: ''

# Generate random two-word codename using custom omgegaconf resolver
shortname: ${randomname:}${descr}

# Time stamp in ISO 8601-like format
# timestamp: ${now:%Y-%m-%d_%H-%M-%S}
timestamp: ${now:%m-%d_%H-%M}

# Version tag
v: v1

hydra:
  run:
    # Where to write logs and config copies
    dir: ${path_prefix}/${v}/${hydra.job.name}/${timestamp}_${shortname}

# Log config values with module logger
log_config: true

enable_zarr_results: false  # warning: concurrent writes possible
device: cuda


labels:
  aff:
    nhood: [[-1, 0, 0], [0, -1, 0], [0, 0, -1]]
  lsd:
    sigma: 120
    downsample: 2
    # sigma: 108
    # downsample: 4


wandb:
  ## These are directly passed to wandb.init() as **kwargs
  init_cfg:
    dir: ${path_prefix}/${v}/
    entity: mdth
    project: nseg
    name: ${shortname}
    tags:
      - mtlsd
  # Visualization options
  vis:
    enable_binary_labels: true
  # Log metrics per cube with filename suffix in addition to mean metrics
  enable_per_cube_metrics: true
  # Include only files with these extensions
  code_include_fn_exts: ['.py', '.json', '.yaml', '.txt']

training:
  iterations: 400001
  save_every: 2000
  # save_every: 2
  # seed: 0  # TODO: Enable in training, make sure forked processes reseed!

  ## Performance options

  # num_workers: auto
  # num_workers: 0
  num_workers: 32
  enable_amp: true
  enable_dynamo: false
  enable_cudnn_benchmark: true

  ## Main hyperparams

  batch_size: 1
  lr: 0.5e-4

  # batch_size: 16
  # lr: 1.0e-3

  save_jit: null


eval:
  max_eval_cubes: null  # Don't limit eval cubes (default)
  # max_eval_cubes: 1  # Only do eval on first cube, skip others
  cube_root: ${dataset.val_root}
  checkpoint_path: /u/mdraw/lsdex/v1/train_mtlsd/2023-04-14_04-02-04/model_checkpoint_20750_state_dict.pth
  result_zarr_root: ${path_prefix}/${v}/eval_zarr/
  merge_function: hist_quant_75
  # threshold: 0.043
  threshold: 1.0
  fragment_threshold: 0.5

  # roi_shape: [250, 250, 250]
  roi_shape: null

  write_groups:
    - raw0
    - gt_seg
    - pred_frag
    - pred_seg
