# Common path prefix
path_prefix: ${oc.env:HOME}/lsdex

# Short description for manually tagging runs, to be set via hydra CLI
descr: ''

# Generate random two-word codename using custom OmegaConf / NConf resolver
#shortname: ${randomname:}${descr}

timestamp: ${now:%m-%d_%H-%M}

# Version tag
v: v1

#roi: 11_micron  # smallest ROI
roi: benchmark  # largest ROI

# Get setup name from custom OmegaConf / NConf resolver based on model path
setup: ${setupname:${i1_predict.model_path}}_${roi}

output_dir : ${path_prefix}/${v}/inference/${setup}


hydra:
  run:
    # Where to write logs and config copies
     dir: ${output_dir}/${hydra.job.name}-hydra/
#     dir: ${path_prefix}/${v}/inference/${hydra.job.name}/${setup}
#     dir: ${path_prefix}/${v}/${setup}/${hydra.job.name}/${timestamp}_${shortname}
#    dir: ${path_prefix}/${v}/inference/${setup}/${hydra.job.name}



meta:
  jobs_to_run:
    - i1
    - i2
    - i3
    - i4
    - i5
    - i6
  evaluate_on:
    - val
    - test
  run_i456_locally: false
#  run_i456_locally: true
  compute_node_slurm_options: ["--ntasks=1", "--time=7-0", "--mem=1000G", "--cpus-per-task=64", "--job-name=i456"]
  submitit_i456_options:
    name: i456
    mem_gb: 1000
    cpus_per_task: 64
    timeout_min: 10080  # 7 days

common:
  roi: ${roi}
  experiment: zebrafinch
  setup: ${setup}
  db_host: cajalg001
  db_name: ${setup}

  voxel_size: [20, 9, 9]
  block_size: [3600, 3600, 3600]
  context: [240, 243, 243]

  # raw_file: /cajal/scratch/projects/misc/mdraw/data/nseg_roi_containers/zf_benchmark_roi.json
  raw_file: ${path_prefix}/data/nseg_roi_containers/zf_${common.roi}_roi.json
  mask_file: ${path_prefix}/data/funke/zebrafinch/testing/ground_truth/data.zarr


  # Output path (affinities, ...)
  out_file: ${output_dir}/affs.zarr
  affs_file: ${common.out_file}
  fragments_file: ${output_dir}/frag.zarr
  seg_file: ${output_dir}/seg.zarr

  pybin: /cajal/scratch/projects/misc/mdraw/anaconda3/envs/nseg/bin/python

  raw_dataset: volumes/raw
  mask_dataset: volumes/neuropil_mask
  affs_dataset: /volumes/pred_affs
  fragments_dataset: /volumes/fragments
  seg_dataset: volumes/segmentation

  run_type: ${common.roi}_roi_masked
  edges_collection: edges_${i3_agglomerate.merge_function}


i1_predict:
#  model_path: /u/mdraw/lsdex/v1/train_mtlsd/08-18_17-42_glum-coffer_resc_hl_ela_cps1044/model_checkpoint_400000.pt
#  model_path: /u/mdraw/lsdex/v1/train_mtlsd/08-20_01-10_muted-modulation_orig_lsd_combined_sw_j0126_v2_synth550_r1_q2/model_checkpoint_400000.pt
#  model_path: /u/mdraw/lsdex/v1/train_mtlsd/08-20_00-26_fat-microphone_orig_lsd_noval_mtrepro_q4/model_checkpoint_400000.pt
  model_path: /u/mdraw/lsdex/v1/train_mtlsd/08-19_01-34_absolute-image_orig_lsd_noval_mtrepro_q2/model_checkpoint_400000.pt

  num_workers: 100
  slurm_options: ["--ntasks=1", "--time=7-0", "--mem=125G", "--cpus-per-task=8", "--gres=gpu:1", "--job-name=ns01pr"]

#  net_input_shape: [96, 484, 484]
  net_input_shape: [192, 484, 484]
#  net_offset: [40, 40, 40]
  net_offset: [36, 212, 212]

  output_cfg:
    pred_affs:       {idx: 1, out_dims:  3, out_dtype: uint8,   squeeze: true, scale: 255  }
    pred_lsds:       {idx: 0, out_dims: 10, out_dtype: uint8,   squeeze: true, scale: 255  }

#    pred_boundaries: {idx: 2, out_dims:  1, out_dtype: uint8,   squeeze: true, scale: 255  }
#    pred_hardness:   {idx: 3, out_dims:  1, out_dtype: float32, squeeze: true, scale:   1.0}

## Known to work, fall back if something breaks
#i2_extract_fragments:
#  num_workers: 100
#  fragments_in_xy: True
#  epsilon_agglomerate: 0.1
#  filter_fragments: 0.05
#  slurm_options: ["--ntasks=1", "--time=1-0", "--mem=200G", "--cpus-per-task=30", "--job-name=ns02ex"]

i2_extract_fragments:
  num_workers: 200
  fragments_in_xy: True
  epsilon_agglomerate: 0.1
  filter_fragments: 0.05
  slurm_options: ["--ntasks=1", "--time=7-0", "--mem=250G", "--cpus-per-task=16", "--job-name=ns02ex"]

## Known to work, fall back if something breaks
#i3_agglomerate:
#  num_workers: 100
#  merge_function: hist_quant_75
#  slurm_options: ["--ntasks=1", "--time=1-0", "--mem=400G", "--cpus-per-task=30", "--job-name=ns03ag"]

i3_agglomerate:
  num_workers: 100
  merge_function: hist_quant_75
#  slurm_options: ["--ntasks=1", "--time=7-0", "--mem=500G", "--cpus-per-task=32", "--job-name=ns03ag"]
  slurm_options: ["--ntasks=1", "--time=7-0", "--mem=250G", "--cpus-per-task=16", "--job-name=ns03ag"]


i4_find_segments:
  num_workers: 32
  thresholds_minmax: [0.0, 0.52]
  thresholds_step: 0.02

i5_evaluate_annotations:
  num_workers: 8
  edges_db_host: ${common.db_host}
  edges_db_name: ${common.db_name}
  annotations_db_host: ${common.db_host}
  annotations_db_names:
    val: val_annotations
    test: test_annotations
  scores_db_name: scores
  scores_collection_names:
    val: ${setup}_val
    test: ${setup}_test

  plot_dir: ${path_prefix}/${v}/evaluation/score_plots
  wandb_dir: ${path_prefix}/${v}/evaluation

#  annotations_db_name: val_annotations  # validation set
#  annotations_db_name: test_annotations  # test set
#  scores_db_name: scores_${common.db_name}_${.annotations_db_name}

  annotations_skeletons_collection_name: zebrafinch
  node_components: zebrafinch_components
  node_mask: zebrafinch_mask
  tuning_metric: erl  # select either erl or voi for selection of best validation threshold that is then applied to the test run
  # roi_offset: [4000, 7200, 4500]  # benchmark_roi
  # roi_shape: [106000, 83700, 87300]  # benchmark_roi
#  thresholds_minmax: [0.4, 1]
#  thresholds_step: 1
#  thresholds_minmax: [0.0, 0.52]
  thresholds_minmax: [0.0, 0.52]
  thresholds_step: 0.02

i6_extract_segmentation:
  # 8 workers with block_size 36000^3 need at least 230 GB RAM just for loading fragments,
  # but occasionally we still get OOM errors even with 8 x 21600^3, so the actual peak memory usage can be much higher.
  num_workers: 6
  block_size: [21600, 21600, 21600]  # override block_size because larger blocks make more sense here
#  threshold: 0.5
  threshold: best_voi
#  threshold: best_erl
